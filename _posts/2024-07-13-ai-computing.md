---
layout: post
title: "Generative AI and Computing Education"
date: "2024-07-13 18:00:00 +0000"
author: Miles Berry
permalink: /2024/07/ai-computing/
comments: true
image:
        feature: 240713.jpg
---

Generative AI is transforming many industries, but its implications for computing education are particularly profound. As the technology evolves, educators must navigate how to integrate it into curricula, equip students with essential skills, and address the ethical challenges it presents.

The Department for Education has recognised the importance of generative AI, encouraging schools to teach students how to use emerging technologies safely and appropriately. While not a statutory requirement, this guidance signals a shift in computing education, where AI literacy is becoming as critical as coding skills. However, accessibility remains a challenge. Many AI tools have age restrictions, limiting their use in primary education, while secondary schools must navigate parental consent requirements.

Computing education is already aligned with many AI principles. The English Computing curriculum emphasises evaluating and applying new technologies to solve problems. This broad aim allows for the inclusion of generative AI, particularly within problem-solving activities and discussions on algorithmic processes. For younger students, AI can be introduced through recognising common uses of technology beyond school, such as smart assistants and the sort of language models built into tablet computers. By Key Stage 3, students can engage with AI more deeply, exploring how machine learning algorithms function and how they differ from traditional programming paradigms.

A fundamental shift in computing education involves rethinking how computers process information. Traditional models focus on deterministic programming: input leads to output via a predefined program. Generative AI disrupts this, introducing probabilistic models where outputs depend on training data and algorithmic interpretation rather than explicit instructions. Debugging in this context is less about fixing syntax errors and more about questioning data quality, model choice, and ethical implications. These are complex issues, but they reflect the real-world challenges that computing students must be prepared for.

Introducing generative AI into the classroom also offers opportunities to improve pedagogy. Teachers can use AI to streamline lesson planning, generate assessment materials, and provide real-time feedback on student work. Tools like ChatGPT can assist in drafting lesson plans, but they should be treated as starting points rather than complete solutions. AI-generated content often lacks pedagogical nuance and can reinforce outdated teaching methods unless critically refined by educators.

There are also concerns about student use of AI for coursework and homework. While generative AI can provide explanations, suggest ideas, and offer feedback, there is a fine line between using AI as an assistive tool and relying on it to complete assignments. Schools must establish clear guidelines to ensure students develop their own understanding and skills rather than outsourcing thinking to AI. The challenge for teachers is not just detecting AI-generated work but also fostering a culture where students value their own intellectual contributions.

Assessment practices will need to adapt. Traditional non-exam assessment may become less reliable indicators of student ability if AI tools can generate high-quality responses. Alternative approaches, such as oral examinations, project-based learning, and coding challenges, may become more important to ensure students demonstrate their knowledge authentically. Universities and exam boards are already grappling with these issues, and schools must prepare students for these evolving expectations.

Bias in AI-generated content is another critical issue. Language models learn from existing data, meaning they can perpetuate stereotypes and reinforce societal biases. Educators must teach students how to critically assess AI outputs, question biases, and consider the ethical dimensions of machine-generated information. Without this awareness, students risk accepting AI responses as authoritative rather than interrogating their validity.

Generative AI is also reshaping what it means to be digitally literate. Beyond traditional skills like coding and troubleshooting, students must now understand how AI systems work, their limitations, and their broader impact. Concepts such as prompt engineering, bias mitigation, and model interpretability should become integral parts of the computing curriculum.

Ultimately, the rise of generative AI presents both opportunities and challenges for computing education. It demands a re-evaluation of teaching methods, assessment strategies, and ethical considerations. Computing educators must lead the way in ensuring students are not just passive consumers of AI but critical thinkers who understand its inner workings, strengths, and risks. By doing so, we can prepare students for a future where AI is an integral part of their digital world, ensuring they have the skills to shape and interrogate the technology rather than being shaped by it.

*Based on [my presentation](https://www.youtube.com/watch?v=Jdvi3xC3ZP0) at the Computing At School annual conference, 13 July 2024, ADA College.*
