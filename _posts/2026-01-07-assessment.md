---     

layout: post     
title: "Assessment in computing"     
date: "2026-01-07 18:00:00 +0000"
author: Miles Berry
permalink: /2026/01/assessment/
comments: true
image:
     feature: 260107.jpg
---

Assessment is central to effective teaching because it provides information about what pupils understand, what they can do, and what they need next. When used well, it supports instructional decisions, enables meaningful feedback, and helps pupils regulate their own learning over time.  Assessment therefore functions not as an endpoint but as part of the learning process itself.

At its simplest, pupil progress means that by the end of a period of learning pupils know more or can do more than they could before.  Demonstrating this requires comparison across time, typically through a baseline followed by a later measure. Without that comparison, evidence shows attainment rather than progress.  

Even when improvement is visible, caution is needed. Showing that pupils improved does not prove that a specific assessment approach caused that improvement. Establishing causation would require comparison with an alternative condition or control group, which is rarely feasible in classroom settings.  For this reason, classroom evidence about assessment is usually suggestive rather than definitive.

This leads to a critical distinction between **measuring learning** and **supporting learning**. Repeated testing alone is unlikely to generate substantial gains, since testing consumes time that might otherwise be used for teaching. The value of assessment lies in how the resulting information shapes subsequent teaching and pupil action, not in the act of testing itself.  

### What assessment looks like in computing

In computing, assessment tends to take two broad forms. One approach asks questions to reveal what pupils know. The other examines tasks or projects to see what pupils can do with that knowledge.  Both are necessary because the subject combines conceptual understanding with practical application. Knowledge without use is incomplete, while performance without understanding is fragile.  

A further dimension concerns pupil disposition. Engagement, effort, and attitude influence outcomes even where knowledge and skill appear similar, although such qualities are harder to measure reliably.  This highlights the limits of purely quantitative assessment.

Different assessment methods foreground different aspects of learning. Multiple-choice questions can provide rapid, reliable insight into knowledge and misconceptions, while programming projects reveal application, creativity, and integration of ideas. Comparative judgement can produce robust ordering of complex work through pairwise comparison rather than fixed marking schemes. AI-supported marking may improve efficiency yet raises professional and ethical considerations.  No single approach captures the full richness of computing learning, so balanced practice draws on several forms.

### Purposes and consequences of assessment

Assessment serves multiple purposes: diagnosing prior knowledge, guiding teaching, providing feedback, motivating effort, and certifying attainment. High-quality feedback should be accurate, clear, and specific, enabling pupils to improve and gradually take ownership of their learning.  When feedback cannot be acted upon, its educational value diminishes.

Teachers must also consider workload and practicality. Assessment that is theoretically sound but operationally burdensome may reduce teaching quality overall. Collaborative approaches and efficient systems help maintain manageability.  

A persistent risk is confusing **activity** with **learning**. Visible engagement or busy classrooms do not guarantee conceptual change. Assessment must therefore probe underlying understanding rather than surface participation.  

### Competing views of knowledge and assessment

Two broad perspectives shape thinking about assessment in computing. One emphasises objective measurement of knowledge through structured questions, numerical scores, and quantitative data. This view aligns with traditions that treat learning as observable response and the subject as a body of academic knowledge.  

The other emphasises construction, creativity, and making. Here, assessment focuses on artefacts, criteria, and qualitative judgement, reflecting the idea that technology and knowledge are socially constructed and best learned through practice.  

Computing education contains elements of both traditions. Effective assessment therefore integrates conceptual questioning with evaluation of practical work. Neither perspective alone is sufficient.  

### Validity, reliability, fairness, and manageability

Sound assessment rests on four key principles. Validity concerns whether an assessment measures what it intends. Reliability concerns consistency of results. Fairness requires equal validity for different groups of learners. Manageability ensures feasibility within available time and resources.  

These principles often exist in tension. Highly authentic project work may enhance validity yet reduce reliability. Frequent testing may increase reliability yet narrow the curriculum or inflate workload. Judgement is therefore required to balance competing demands.

### Assessment, curriculum, and accountability

Assessment practices shape what is taught. Strong emphasis on examinations can narrow curriculum experience toward what is tested, while broader curricula may support richer understanding but risk weaker measurable outcomes.  

Examination systems rely on precise command words and structured responses rather than open questioning, reinforcing the need to teach pupils how to interpret assessment demands.  At the same time, over-general competency statements may obscure the specific knowledge required for genuine expertise.  

Balanced assessment must therefore preserve disciplinary knowledge while enabling meaningful application and creativity.

### Progress, evidence, and professional judgement

Evidence of progress typically involves comparison between earlier and later performance, whether through tests, projects, or other artefacts.  Yet interpretation always requires professional judgement. Improvement may result from teaching quality, time, maturation, or motivation as much as from assessment design.

Consequently, the central professional task is not to prove that one assessment method universally works, but to use assessment intelligently to support learning in specific contexts. This involves selecting appropriate methods, interpreting evidence critically, and adapting teaching in response.

### Concluding perspective

Assessment in computing is complex because the subject itself combines knowledge, skill, creativity, and disposition. Effective practice cannot rely solely on tests or projects, nor on quantitative or qualitative evidence alone. Instead, it requires thoughtful integration guided by validity, reliability, fairness, and manageability.

Above all, assessment should serve learning. Its purpose is not merely to measure what pupils know, but to help them know more and do more over time.

*Based on the 12th Roehampton Computing Education lecture, Assessment, 7 January 2026*